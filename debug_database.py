#!/usr/bin/env python3
"""
Database Debug Viewer
=====================
A comprehensive tool to view all database information clearly for debugging.
Shows projects, datasets, images, and their relationships in a readable format.

Usage: python debug_database.py
"""

import sqlite3
import os
from datetime import datetime
from pathlib import Path
import json
import hashlib

class DatabaseDebugger:
    def __init__(self, db_path="database.db"):
        self.db_path = db_path
        self.conn = None
        
    def connect(self):
        """Connect to the database"""
        if not os.path.exists(self.db_path):
            print(f"âŒ Database not found: {self.db_path}")
            return False
        
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.conn.row_factory = sqlite3.Row  # Enable column access by name
            print(f"âœ… Connected to database: {self.db_path}")
            return True
        except Exception as e:
            print(f"âŒ Failed to connect to database: {e}")
            return False
    
    def close(self):
        """Close database connection"""
        if self.conn:
            self.conn.close()
    
    def print_header(self, title, char="="):
        """Print a formatted header"""
        print(f"\n{char * 80}")
        print(f"{title:^80}")
        print(f"{char * 80}")
    
    def print_subheader(self, title, char="-"):
        """Print a formatted subheader"""
        print(f"\n{char * 60}")
        print(f"{title:^60}")
        print(f"{char * 60}")
    
    def get_table_info(self):
        """Get information about all tables in the database"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = cursor.fetchall()
        
        self.print_header("DATABASE SCHEMA INFORMATION")
        
        for table in tables:
            table_name = table[0]
            print(f"\nğŸ“‹ Table: {table_name}")
            
            # Get table schema
            cursor.execute(f"PRAGMA table_info({table_name});")
            columns = cursor.fetchall()
            
            print("   Columns:")
            for col in columns:
                col_info = f"   - {col[1]} ({col[2]})"
                if col[3]:  # NOT NULL
                    col_info += " NOT NULL"
                if col[4] is not None:  # Default value
                    col_info += f" DEFAULT {col[4]}"
                if col[5]:  # Primary key
                    col_info += " PRIMARY KEY"
                print(col_info)
            
            # Get row count
            cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
            count = cursor.fetchone()[0]
        print(f"   ğŸ“Š Total rows: {count}")

    def get_training_sessions_table(self):
        """Detailed info about training_sessions table"""
        cursor = self.conn.cursor()
        self.print_header("TRAINING SESSIONS TABLE")
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='training_sessions'")
        if not cursor.fetchone():
            print("âŒ training_sessions table does not exist!")
            return
        print("\nğŸ“ Schema:")
        cursor.execute("PRAGMA table_info('training_sessions')")
        for col in cursor.fetchall():
            col_info = f"   - {col[1]} ({col[2]})"
            if col[3]:
                col_info += " NOT NULL"
            if col[4] is not None:
                col_info += f" DEFAULT {col[4]}"
            if col[5]:
                col_info += " PRIMARY KEY"
            print(col_info)
        print("\nğŸ” Indexes:")
        cursor.execute("PRAGMA index_list('training_sessions')")
        idx_list = cursor.fetchall()
        if idx_list:
            for idx in idx_list:
                idx_name = idx[1]
                is_unique = bool(idx[2]) if len(idx) > 2 else False
                print(f"   - {idx_name} {'(UNIQUE)' if is_unique else ''}")
                try:
                    cursor.execute(f"PRAGMA index_info('{idx_name}')")
                    cols = ", ".join([r[2] for r in cursor.fetchall()])
                    print(f"     Columns: {cols}")
                except Exception as e:
                    print(f"     âš ï¸  Could not read index columns: {e}")
        else:
            print("   (no indexes)")
        cursor.execute("SELECT COUNT(*) FROM training_sessions")
        count = cursor.fetchone()[0]
        print(f"\nğŸ“Š Total rows: {count}")
        if count:
            print("\nğŸ—‚ï¸  Recent Sessions:")
            cursor.execute("""
                SELECT 
                    id, training_uid, name,
                    project_id, project_name,
                    base_model_id, dataset_release_id, dataset_release_dir, dataset_summary_json,
                    framework, task, model_name,
                    run_dir, weights_dir, best_weights_path, logs_dir, artifacts_dir,
                    status, progress_pct,
                    best_epoch,
                    best_box_map50, best_box_map95,
                    best_mask_map50, best_mask_map95,
                    created_at, started_at, last_update_at, completed_at,
                    error_msg
                FROM training_sessions
                ORDER BY created_at DESC
                LIMIT 10
            """)
            for row in cursor.fetchall():
                print(f"   â–¶ï¸ {row['name']} (ID: {row['id']}) â€¢ UID: {row['training_uid'] or 'N/A'}")
                print(f"      ğŸ—ï¸  Project: {row['project_name']} (ID: {row['project_id']})")
                print(f"\n      ğŸ”— Links:")
                print(f"         Base Model: {row['base_model_id']}")
                print(f"         Release ID: {row['dataset_release_id']}")
                print(f"         Release Dir: {row['dataset_release_dir']}")
                if row['dataset_summary_json']:
                    print(f"         Dataset Summary JSON: present")
                else:
                    print(f"         Dataset Summary JSON: N/A")
                print(f"\n      ğŸ›ï¸  Context:")
                print(f"         Framework: {row['framework'] or 'N/A'} â€¢ Task: {row['task'] or 'N/A'} â€¢ Model Name: {row['model_name'] or 'N/A'}")
                print(f"\n      ğŸ“‚ Paths:")
                print(f"         run_dir: {row['run_dir'] or 'N/A'}")
                print(f"         weights_dir: {row['weights_dir'] or 'N/A'}")
                print(f"         best_weights_path: {row['best_weights_path'] or 'N/A'}")
                print(f"         logs_dir: {row['logs_dir'] or 'N/A'}")
                print(f"         artifacts_dir: {row['artifacts_dir'] or 'N/A'}")
                print(f"\n      ğŸ“ˆ Status:")
                print(f"         {row['status']} â€¢ Progress: {row['progress_pct']}%")
                print(f"\n      ğŸ… Quick Metrics:")
                print(f"         Best Epoch: {row['best_epoch'] if row['best_epoch'] is not None else 'N/A'}")
                print(f"         Box mAP: 50={row['best_box_map50'] if row['best_box_map50'] is not None else 'N/A'} â€¢ 95={row['best_box_map95'] if row['best_box_map95'] is not None else 'N/A'}")
                print(f"         Mask mAP: 50={row['best_mask_map50'] if row['best_mask_map50'] is not None else 'N/A'} â€¢ 95={row['best_mask_map95'] if row['best_mask_map95'] is not None else 'N/A'}")
                print(f"\n      ğŸ“… Timestamps:")
                print(f"         Created: {row['created_at']} â€¢ Started: {row['started_at']} â€¢ Updated: {row['last_update_at']} â€¢ Completed: {row['completed_at']}")
                if row['error_msg']:
                    print(f"\n      â— Error: {row['error_msg']}")
    
    def get_projects_overview(self):
        """Get overview of all projects"""
        cursor = self.conn.cursor()
        
        self.print_header("PROJECTS OVERVIEW")
        
        cursor.execute("SELECT * FROM projects ORDER BY created_at;")
        projects = cursor.fetchall()
        
        if not projects:
            print("âŒ No projects found in database")
            return
        
        for project in projects:
            print(f"\nğŸ—ï¸  PROJECT: {project['name']} (ID: {project['id']})")
            print(f"   ğŸ“ Description: {project['description']}")
            print(f"   ğŸ“… Created: {project['created_at']}")
            print(f"   ğŸ”„ Updated: {project['updated_at']}")
            
            # Get project statistics
            cursor.execute("SELECT COUNT(*) FROM datasets WHERE project_id = ?", (project['id'],))
            dataset_count = cursor.fetchone()[0]
            
            cursor.execute("""
                SELECT COUNT(*) FROM images i 
                JOIN datasets d ON i.dataset_id = d.id 
                WHERE d.project_id = ?
            """, (project['id'],))
            image_count = cursor.fetchone()[0]
            
            print(f"   ğŸ“Š Datasets: {dataset_count}")
            print(f"   ğŸ–¼ï¸  Total Images: {image_count}")
    
    def get_datasets_detailed(self):
        """Get detailed information about all datasets"""
        cursor = self.conn.cursor()
        
        self.print_header("DATASETS DETAILED VIEW")
        
        cursor.execute("""
            SELECT d.*, p.name as project_name 
            FROM datasets d 
            JOIN projects p ON d.project_id = p.id 
            ORDER BY p.name, d.created_at
        """)
        datasets = cursor.fetchall()
        
        if not datasets:
            print("âŒ No datasets found in database")
            return
        
        current_project = None
        for dataset in datasets:
            if current_project != dataset['project_name']:
                current_project = dataset['project_name']
                self.print_subheader(f"PROJECT: {current_project}")
            
            print(f"\nğŸ“ DATASET: {dataset['name']} (ID: {dataset['id']})")
            print(f"   ğŸ“ Description: {dataset['description']}")
            print(f"   ğŸ“… Created: {dataset['created_at']}")
            print(f"   ğŸ”„ Updated: {dataset['updated_at']}")
            
            # Get dataset statistics and split types
            cursor.execute("SELECT COUNT(*) FROM images WHERE dataset_id = ?", (dataset['id'],))
            total_images = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM images WHERE dataset_id = ? AND is_labeled = 1", (dataset['id'],))
            labeled_images = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM images WHERE dataset_id = ? AND is_labeled = 0", (dataset['id'],))
            unlabeled_images = cursor.fetchone()[0]
            
            # Get split types for this dataset
            cursor.execute("SELECT split_type, COUNT(*) FROM images WHERE dataset_id = ? GROUP BY split_type", (dataset['id'],))
            split_types = cursor.fetchall()
            
            print(f"   ğŸ“Š Total Images: {total_images}")
            print(f"   âœ… Labeled: {labeled_images}")
            print(f"   âŒ Unlabeled: {unlabeled_images}")
            
            if split_types:
                print(f"   ğŸ”€ Split Sections:")
                for split_type, count in split_types:
                    print(f"      - {split_type}: {count} images")
                    
                    # Check if physical folder exists for each split type
                    expected_folder = f"projects/{dataset['project_name']}/{split_type}/{dataset['name']}"
                    folder_exists = os.path.exists(expected_folder)
                    print(f"        ğŸ“‚ Folder: {expected_folder} {'âœ…' if folder_exists else 'âŒ'}")
            else:
                print(f"   ğŸ”€ Split Sections: None")
    
    def get_images_detailed(self):
        """Get detailed information about all images"""
        cursor = self.conn.cursor()
        
        self.print_header("IMAGES DETAILED VIEW")
        
        cursor.execute("""
            SELECT i.*, d.name as dataset_name, p.name as project_name
            FROM images i 
            JOIN datasets d ON i.dataset_id = d.id 
            JOIN projects p ON d.project_id = p.id 
            ORDER BY p.name, d.name, i.filename
        """)
        images = cursor.fetchall()
        
        if not images:
            print("âŒ No images found in database")
            return
        
        current_project = None
        current_dataset = None
        
        for image in images:
            if current_project != image['project_name']:
                current_project = image['project_name']
                self.print_subheader(f"PROJECT: {current_project}")
            
            if current_dataset != image['dataset_name']:
                current_dataset = image['dataset_name']
                print(f"\nğŸ“ Dataset: {current_dataset}")
            
            print(f"\n   ğŸ–¼ï¸  IMAGE: {image['filename']} (ID: {image['id']})")
            print(f"      ğŸ“‚ File Path: {image['file_path']}")
            print(f"      ğŸ“ Size: {image['width']}x{image['height']}")
            print(f"      ğŸ”€ Split Type: {image['split_type']}")
            
            # Check if split_section column exists in the database
            try:
                split_section = image['split_section']
                print(f"      ğŸ·ï¸  Split Section: {split_section}")
            except:
                print(f"      ğŸ·ï¸  Split Section: Column not found in database")
                
            print(f"      âœ… Labeled: {'Yes' if image['is_labeled'] else 'No'}")
            print(f"      ğŸ¤– Auto-labeled: {'Yes' if image['is_auto_labeled'] else 'No'}")
            print(f"      âœ”ï¸  Verified: {'Yes' if image['is_verified'] else 'No'}")
            print(f"      ğŸ“… Created: {image['created_at']}")
            print(f"      ğŸ”„ Updated: {image['updated_at']}")
            
            # Check if physical file exists
            file_exists = os.path.exists(image['file_path'])
            print(f"      ğŸ’¾ Physical File: {'âœ… Exists' if file_exists else 'âŒ Missing'}")
            
            # Get annotations count
            cursor.execute("SELECT COUNT(*) FROM annotations WHERE image_id = ?", (image['id'],))
            annotation_count = cursor.fetchone()[0]
            print(f"      ğŸ¯ Annotations: {annotation_count}")
    
    def get_annotations_summary(self):
        """Get summary of annotations"""
        cursor = self.conn.cursor()
        
        self.print_header("ANNOTATIONS SUMMARY")
        
        cursor.execute("""
            SELECT 
                p.name as project_name,
                d.name as dataset_name,
                i.filename,
                COUNT(a.id) as annotation_count,
                GROUP_CONCAT(DISTINCT a.class_name) as labels
            FROM annotations a
            JOIN images i ON a.image_id = i.id
            JOIN datasets d ON i.dataset_id = d.id
            JOIN projects p ON d.project_id = p.id
            GROUP BY p.name, d.name, i.filename
            ORDER BY p.name, d.name, i.filename
        """)
        annotations = cursor.fetchall()
        
        if not annotations:
            print("âŒ No annotations found in database")
            return
        
        current_project = None
        current_dataset = None
        
        for ann in annotations:
            if current_project != ann['project_name']:
                current_project = ann['project_name']
                self.print_subheader(f"PROJECT: {current_project}")
            
            if current_dataset != ann['dataset_name']:
                current_dataset = ann['dataset_name']
                print(f"\nğŸ“ Dataset: {current_dataset}")
            
            labels = ann['labels'].split(',') if ann['labels'] else []
            print(f"   ğŸ–¼ï¸  {ann['filename']}: {ann['annotation_count']} annotations")
            if labels:
                print(f"      ğŸ·ï¸  Labels: {', '.join(labels)}")

    def get_image_transformations_detailed(self):
        """Get detailed information about image transformations and dual-value system"""
        cursor = self.conn.cursor()
        
        self.print_header("IMAGE TRANSFORMATIONS & DUAL-VALUE SYSTEM")
        
        # Check if image_transformations table exists
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='image_transformations';")
        table_exists = cursor.fetchone()
        
        if not table_exists:
            print("âŒ image_transformations table not found in database")
            return
        
        # Get all transformations
        cursor.execute("""
            SELECT * FROM image_transformations 
            ORDER BY release_version, order_index, transformation_type
        """)
        transformations = cursor.fetchall()
        
        if not transformations:
            print("âŒ No image transformations found in database")
            return
        
        current_release = None
        for trans in transformations:
            if current_release != trans['release_version']:
                current_release = trans['release_version']
                self.print_subheader(f"RELEASE VERSION: {current_release}")
                
                # Get release statistics
                cursor.execute("""
                    SELECT 
                        COUNT(*) as total_transformations,
                        COUNT(CASE WHEN is_dual_value = 1 THEN 1 END) as dual_value_count,
                        COUNT(CASE WHEN is_enabled = 1 THEN 1 END) as enabled_count,
                        MAX(transformation_combination_count) as max_images,
                        MAX(user_selected_images_per_original) as user_selected
                    FROM image_transformations 
                    WHERE release_version = ?
                """, (current_release,))
                stats = cursor.fetchone()
                
                print(f"   ğŸ“Š Release Statistics:")
                print(f"      Total Transformations: {stats['total_transformations']}")
                print(f"      Dual-Value Tools: {stats['dual_value_count']}")
                print(f"      Enabled Tools: {stats['enabled_count']}")
                print(f"      Max Images per Original: {stats['max_images'] if stats['max_images'] else 'Not calculated'}")
                print(f"      Images per Original (User Choice): {stats['user_selected'] if stats['user_selected'] else 'Not set'}")
            
            print(f"\n   ğŸ”§ TRANSFORMATION: {trans['transformation_type']} (ID: {trans['id'][:8]}...)")
            print(f"      ğŸ“ Category: {trans['category'] if trans['category'] else 'N/A'}")
            print(f"      ğŸ”¢ Order Index: {trans['order_index']}")
            print(f"      âœ… Enabled: {'Yes' if trans['is_enabled'] else 'No'}")
            print(f"      ğŸ”„ Status: {trans['status'] if trans['status'] else 'N/A'}")
            
            # Dual-value system information
            print(f"      ğŸ¯ Dual-Value System:")
            print(f"         Is Dual-Value: {'Yes' if trans['is_dual_value'] else 'No'}")
            print(f"         Dual-Value Enabled: {'Yes' if trans['dual_value_enabled'] else 'No'}")
            
            # Parameters
            if trans['parameters']:
                try:
                    params = json.loads(trans['parameters']) if isinstance(trans['parameters'], str) else trans['parameters']
                    print(f"      âš™ï¸  Parameters: {json.dumps(params, indent=10)}")
                except:
                    print(f"      âš™ï¸  Parameters: {trans['parameters']}")
            
            # Dual-value parameters
            if trans['dual_value_parameters']:
                try:
                    dual_params = json.loads(trans['dual_value_parameters']) if isinstance(trans['dual_value_parameters'], str) else trans['dual_value_parameters']
                    print(f"      ğŸ­ Dual-Value Parameters: {json.dumps(dual_params, indent=10)}")
                except:
                    print(f"      ğŸ­ Dual-Value Parameters: {trans['dual_value_parameters']}")
            
            # Parameter ranges
            if trans['parameter_ranges']:
                try:
                    ranges = json.loads(trans['parameter_ranges']) if isinstance(trans['parameter_ranges'], str) else trans['parameter_ranges']
                    print(f"      ğŸ“Š Parameter Ranges: {json.dumps(ranges, indent=10)}")
                except:
                    print(f"      ğŸ“Š Parameter Ranges: {trans['parameter_ranges']}")
            
            # Range enabled params
            if trans['range_enabled_params']:
                try:
                    range_params = json.loads(trans['range_enabled_params']) if isinstance(trans['range_enabled_params'], str) else trans['range_enabled_params']
                    print(f"      ğŸ›ï¸  Range Enabled Params: {json.dumps(range_params, indent=10)}")
                except:
                    print(f"      ğŸ›ï¸  Range Enabled Params: {trans['range_enabled_params']}")
            
            # New columns information
            print(f"      ğŸ“ˆ Combination Count: {trans['transformation_combination_count'] if trans['transformation_combination_count'] else 'Not calculated'}")
            print(f"      ğŸ‘¤ Images per Original (User Choice): {trans['user_selected_images_per_original'] if trans['user_selected_images_per_original'] else 'Not set'}")
            
            print(f"      ğŸ“… Created: {trans['created_at']}")
            print(f"      ğŸ”„ Release ID: {trans['release_id'] if trans['release_id'] else 'N/A'}")
        
        # Check for auto-generated values in dual_value_parameters
        self.print_subheader("AUTO-GENERATED VALUES CHECK")
        cursor.execute("""
            SELECT transformation_type, dual_value_parameters 
            FROM image_transformations 
            WHERE dual_value_parameters IS NOT NULL 
            AND dual_value_parameters != 'null'
            AND dual_value_parameters != '{}'
        """)
        auto_gen_data = cursor.fetchall()
        
        if auto_gen_data:
            print("âœ… Found transformations with dual-value parameters (auto-generated values):")
            for row in auto_gen_data:
                print(f"   ğŸ”§ {row['transformation_type']}:")
                try:
                    params = json.loads(row['dual_value_parameters']) if isinstance(row['dual_value_parameters'], str) else row['dual_value_parameters']
                    print(f"      Auto-gen data: {json.dumps(params, indent=8)}")
                except:
                    print(f"      Raw data: {row['dual_value_parameters']}")
        else:
            print("âŒ No auto-generated values found in dual_value_parameters column")
            print("   This might be normal if auto-generation happens at runtime")

    def get_detailed_annotations(self):
        """Get detailed view of all annotations with coordinates"""
        cursor = self.conn.cursor()
        
        self.print_header("DETAILED ANNOTATIONS WITH COORDINATES")
        
        cursor.execute("""
            SELECT 
                a.id,
                a.class_name,
                a.class_id,
                a.confidence,
                a.x_min,
                a.y_min,
                a.x_max,
                a.y_max,
                a.segmentation,
                a.is_auto_generated,
                a.is_verified,
                a.model_id,
                a.created_at,
                a.updated_at,
                p.name as project_name,
                d.name as dataset_name,
                i.filename,
                i.width as image_width,
                i.height as image_height
            FROM annotations a
            JOIN images i ON a.image_id = i.id
            JOIN datasets d ON i.dataset_id = d.id
            JOIN projects p ON d.project_id = p.id
            ORDER BY p.name, d.name, i.filename, a.class_name, a.id
        """)
        annotations = cursor.fetchall()
        
        if not annotations:
            print("âŒ No annotations found in database")
            return
        
        current_project = None
        current_dataset = None
        current_image = None
        
        for ann in annotations:
            if current_project != ann['project_name']:
                current_project = ann['project_name']
                self.print_subheader(f"PROJECT: {current_project}")
            
            if current_dataset != ann['dataset_name']:
                current_dataset = ann['dataset_name']
                print(f"\nğŸ“ Dataset: {current_dataset}")
            
            if current_image != ann['filename']:
                current_image = ann['filename']
                print(f"\n   ğŸ–¼ï¸  IMAGE: {ann['filename']} ({ann['image_width']}x{ann['image_height']})")
            
            print(f"\n      ğŸ¯ ANNOTATION #{ann['id'][:8]}...")
            print(f"         ğŸ·ï¸  Label: {ann['class_name']} (Class ID: {ann['class_id']})")
            print(f"         ğŸ“Š Confidence: {ann['confidence'] if ann['confidence'] else 'N/A'}")
            print(f"         ğŸ¤– Auto-generated: {'Yes' if ann['is_auto_generated'] else 'No'}")
            print(f"         âœ”ï¸  Verified: {'Yes' if ann['is_verified'] else 'No'}")
            print(f"         ğŸ”§ Model ID: {ann['model_id'] if ann['model_id'] else 'Manual'}")
            print(f"         ğŸ“… Created: {ann['created_at']}")
            print(f"         ğŸ”„ Updated: {ann['updated_at']}")
            
            # Display bounding box coordinates
            if ann['x_min'] is not None and ann['y_min'] is not None:
                width = ann['x_max'] - ann['x_min']
                height = ann['y_max'] - ann['y_min']
                print(f"         ğŸ“ Bounding Box:")
                print(f"            ğŸ“¦ Top-Left: ({ann['x_min']}, {ann['y_min']})")
                print(f"            ğŸ“¦ Bottom-Right: ({ann['x_max']}, {ann['y_max']})")
                print(f"            ğŸ“ Size: {width:.1f} x {height:.1f}")
                print(f"            ğŸ“ Area: {width * height:.1f} pixels")
                
                # Calculate relative coordinates (percentage of image)
                if ann['image_width'] and ann['image_height']:
                    rel_x_min = (ann['x_min'] / ann['image_width']) * 100
                    rel_y_min = (ann['y_min'] / ann['image_height']) * 100
                    rel_x_max = (ann['x_max'] / ann['image_width']) * 100
                    rel_y_max = (ann['y_max'] / ann['image_height']) * 100
                    print(f"            ğŸ“Š Relative: ({rel_x_min:.1f}%, {rel_y_min:.1f}%) to ({rel_x_max:.1f}%, {rel_y_max:.1f}%)")
            
            # Display segmentation data if available
            if ann['segmentation']:
                try:
                    segmentation = json.loads(ann['segmentation']) if isinstance(ann['segmentation'], str) else ann['segmentation']
                    print(f"         ğŸ”º Segmentation:")
                    
                    if isinstance(segmentation, list) and len(segmentation) > 0:
                        # Check for different segmentation formats
                        if isinstance(segmentation[0], dict) and 'x' in segmentation[0] and 'y' in segmentation[0]:
                            # Format: [{x: x1, y: y1}, {x: x2, y: y2}, ...]
                            print(f"            Polygon: {len(segmentation)} points")
                            for j, point in enumerate(segmentation):  # Show ALL points
                                print(f"               Point {j+1}: ({point['x']:8.2f}, {point['y']:8.2f})")
                        elif isinstance(segmentation[0], list):
                            # Polygon format: [[x1,y1,x2,y2,...]]
                            for i, polygon in enumerate(segmentation):
                                points = [(polygon[j], polygon[j+1]) for j in range(0, len(polygon), 2)]
                                print(f"            Polygon {i+1}: {len(points)} points")
                                for j, (x, y) in enumerate(points):  # Show ALL points
                                    print(f"               Point {j+1}: ({x:8.2f}, {y:8.2f})")
                        elif all(isinstance(x, (int, float)) for x in segmentation):
                            # Single polygon: [x1,y1,x2,y2,...]
                            try:
                                points = [(segmentation[j], segmentation[j+1]) for j in range(0, len(segmentation), 2)]
                                print(f"            Polygon: {len(points)} points")
                                for j, (x, y) in enumerate(points):  # Show ALL points
                                    print(f"               Point {j+1}: ({x:8.2f}, {y:8.2f})")
                            except IndexError:
                                print(f"            âš ï¸ Invalid polygon format: {segmentation}")
                        else:
                            print(f"            ğŸ“‹ Raw: {segmentation}")
                    else:
                        print(f"            ğŸ“‹ Raw: {segmentation}")
                except (json.JSONDecodeError, TypeError, ValueError, IndexError) as e:
                    print(f"            âŒ Error parsing segmentation: {e}")
                    print(f"            ğŸ“‹ Raw: {ann['segmentation']}")
        
        # Summary statistics
        print(f"\nğŸ“Š ANNOTATION STATISTICS:")
        cursor.execute("SELECT COUNT(*) FROM annotations")
        total_annotations = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT class_name) FROM annotations")
        unique_classes = cursor.fetchone()[0]
        
        cursor.execute("SELECT class_name, COUNT(*) as count FROM annotations GROUP BY class_name ORDER BY count DESC")
        class_counts = cursor.fetchall()
        
        print(f"   ğŸ¯ Total Annotations: {total_annotations}")
        print(f"   ğŸ·ï¸  Unique Classes: {unique_classes}")
        print(f"   ğŸ“ˆ Class Distribution:")
        for class_name, count in class_counts:
            percentage = (count / total_annotations) * 100
            print(f"      {class_name}: {count} annotations ({percentage:.1f}%)")
    
    def get_file_system_vs_database(self):
        """Compare file system structure with database records"""
        self.print_header("FILE SYSTEM vs DATABASE COMPARISON")
        
        cursor = self.conn.cursor()
        
        # Get all datasets and their split types from database
        cursor.execute("""
            SELECT d.*, p.name as project_name,
                   GROUP_CONCAT(DISTINCT i.split_type) as split_types
            FROM datasets d 
            JOIN projects p ON d.project_id = p.id
            LEFT JOIN images i ON d.id = i.dataset_id
            GROUP BY d.id, p.name
        """)
        datasets = cursor.fetchall()
        
        print("\nğŸ” CHECKING DATASET FOLDERS:")
        for dataset in datasets:
            project_name = dataset['project_name']
            dataset_name = dataset['name']
            split_types = dataset['split_types'].split(',') if dataset['split_types'] else []
            
            print(f"\nğŸ“ {dataset_name}")
            
            for split_type in split_types:
                if split_type:  # Skip empty split types
                    # Use the correct path format without 'uploads/'
                    expected_path = f"projects/{project_name}/{split_type}/{dataset_name}"
                    exists = os.path.exists(expected_path)
                    
                    print(f"   Split: {split_type}")
                    print(f"   Expected: {expected_path}")
                    print(f"   Status: {'âœ… EXISTS' if exists else 'âŒ MISSING'}")
                    
                    if exists:
                        # Count files in folder
                        try:
                            total_image_files = []
                            
                            # For dataset split type, check for train/val/test subfolders
                            if split_type == "dataset":
                                # First check the main folder for direct files
                                direct_files = list(Path(expected_path).glob("*.*"))
                                direct_image_files = [f for f in direct_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']]
                                total_image_files.extend(direct_image_files)
                                
                                # Check for train/val/test subfolders
                                split_sections = ['train', 'val', 'test']
                                subfolder_details = []
                                
                                for section in split_sections:
                                    section_path = os.path.join(expected_path, section)
                                    if os.path.exists(section_path):
                                        section_files = list(Path(section_path).glob("*.*"))
                                        section_image_files = [f for f in section_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']]
                                        if section_image_files:
                                            total_image_files.extend(section_image_files)
                                            subfolder_details.append(f"{section}: {len(section_image_files)} files")
                                
                                print(f"   Files in folder: {len(total_image_files)}")
                                
                                # Print details of subfolder distribution if any
                                if subfolder_details:
                                    print(f"   Subfolder distribution: {', '.join(subfolder_details)}")
                            else:
                                # For non-dataset split types, just check the folder directly
                                files = list(Path(expected_path).glob("*.*"))
                                total_image_files = [f for f in files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']]
                                print(f"   Files in folder: {len(total_image_files)}")
                            
                            # Count images in database for this dataset and split type
                            cursor.execute("SELECT COUNT(*) FROM images WHERE dataset_id = ? AND split_type = ?", (dataset['id'], split_type))
                            db_count = cursor.fetchone()[0]
                            print(f"   Images in DB: {db_count}")
                            
                            if len(total_image_files) != db_count:
                                print(f"   âš ï¸  MISMATCH: Folder has {len(total_image_files)} files, DB has {db_count} records")
                                if split_type == "dataset" and subfolder_details:
                                    print(f"   â„¹ï¸  NOTE: Files are distributed across train/val/test subfolders")
                        except Exception as e:
                            print(f"   âŒ Error reading folder: {e}")
        
        # Check for orphaned folders
        print(f"\nğŸ” CHECKING FOR ORPHANED FOLDERS:")
        projects_path = "projects"  # Changed from uploads/projects to projects
        if os.path.exists(projects_path):
            for project_folder in os.listdir(projects_path):
                project_path = os.path.join(projects_path, project_folder)
                if os.path.isdir(project_path):
                    for split_folder in os.listdir(project_path):
                        split_path = os.path.join(project_path, split_folder)
                        if os.path.isdir(split_path):
                            for dataset_folder in os.listdir(split_path):
                                dataset_path = os.path.join(split_path, dataset_folder)
                                if os.path.isdir(dataset_path):
                                    # Check if this dataset exists in database
                                    cursor.execute("""
                                        SELECT COUNT(*) FROM datasets d
                                        JOIN projects p ON d.project_id = p.id
                                        JOIN images i ON d.id = i.dataset_id
                                        WHERE p.name = ? AND d.name = ? AND i.split_type = ?
                                    """, (project_folder, dataset_folder, split_folder))
                                    
                                    exists_in_db = cursor.fetchone()[0] > 0
                                    if not exists_in_db:
                                        print(f"   âš ï¸  ORPHANED FOLDER: {dataset_path} (not in database)")
    
    def get_labels_table(self):
        """Get all labels from the labels table"""
        cursor = self.conn.cursor()
        
        self.print_header("LABELS TABLE DATA")
        
        # Check if labels table exists
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='labels'")
        if not cursor.fetchone():
            print("âŒ Labels table does not exist!")
            return
        
        # Get all labels
        cursor.execute("""
            SELECT 
                p.name AS project_name,
                l.id,
                l.name,
                l.color,
                l.project_id
            FROM labels l
            LEFT JOIN projects p ON l.project_id = p.id
            ORDER BY l.project_id
        """)
        
        labels = cursor.fetchall()
        
        if not labels:
            print("âŒ No labels found in the database!")
            return
        
        print(f"ğŸ“‹ Found {len(labels)} labels in database\n")
        
        # Group labels by project
        projects = {}
        for label in labels:
            project_id = label['project_id']
            if project_id not in projects:
                projects[project_id] = {
                    'name': label['project_name'],
                    'labels': []
                }
            projects[project_id]['labels'].append(label)
        
        # Display labels by project
        for project_id, project_data in projects.items():
            self.print_subheader(f"Project: {project_data['name']} (ID: {project_id})")
            
            for label in project_data['labels']:
                print(f"   ğŸ·ï¸  ID: {label['id']}, Name: {label['name']}, Color: {label['color']}")
            
            print(f"   Total: {len(project_data['labels'])} labels\n")
        
        # Check for labels used in annotations
        print("\nğŸ” CHECKING LABELS USAGE IN ANNOTATIONS:")
        for project_id, project_data in projects.items():
            print(f"\n   Project: {project_data['name']} (ID: {project_id})")
            
            for label in project_data['labels']:
                # Count annotations using this label name
                cursor.execute("""
                    SELECT COUNT(*) 
                    FROM annotations 
                    WHERE class_name = ?
                """, (label['name'],))
                
                annotation_count = cursor.fetchone()[0]
                
                # Get list of datasets where this label is used
                cursor.execute("""
                    SELECT DISTINCT d.id, d.name
                    FROM annotations a
                    JOIN images i ON a.image_id = i.id
                    JOIN datasets d ON i.dataset_id = d.id
                    WHERE a.class_name = ? AND d.project_id = ?
                """, (label['name'], project_id))
                
                datasets = cursor.fetchall()
                dataset_names = [d['name'] for d in datasets]
                
                if annotation_count > 0:
                    print(f"      âœ… Label '{label['name']}' used in {annotation_count} annotations")
                    if dataset_names:
                        print(f"         Used in datasets: {', '.join(dataset_names)}")
                else:
                    print(f"      âŒ Label '{label['name']}' not used in any annotations")

    def get_ai_models_table(self):
        """Get detailed information about AI models (ai_models table)"""
        cursor = self.conn.cursor()

        self.print_header("AI MODELS TABLE")

        # Check if ai_models table exists
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='ai_models'")
        if not cursor.fetchone():
            print("âŒ ai_models table does not exist!")
            print("â„¹ï¸  If you just added the model schema, start the backend or run init_database.py to create tables.")
            return

        # Print table schema
        print("\nğŸ“ Schema:")
        cursor.execute("PRAGMA table_info(ai_models);")
        columns = cursor.fetchall()
        for col in columns:
            col_info = f"   - {col[1]} ({col[2]})"
            if col[3]:  # NOT NULL
                col_info += " NOT NULL"
            if col[4] is not None:  # Default value
                col_info += f" DEFAULT {col[4]}"
            if col[5]:  # Primary key
                col_info += " PRIMARY KEY"
            print(col_info)

        # Print indexes
        print("\nğŸ” Indexes:")
        cursor.execute("PRAGMA index_list('ai_models');")
        index_list = cursor.fetchall()
        if index_list:
            for idx in index_list:
                # idx columns: seq, name, unique, origin, partial (SQLite versions may vary)
                idx_name = idx[1]
                is_unique = bool(idx[2]) if len(idx) > 2 else False
                print(f"   - {idx_name} {'(UNIQUE)' if is_unique else ''}")
                try:
                    cursor.execute(f"PRAGMA index_info('{idx_name}');")
                    idx_cols = cursor.fetchall()
                    cols = ", ".join([c[2] for c in idx_cols]) if idx_cols else "(unknown columns)"
                    print(f"     Columns: {cols}")
                except Exception as e:
                    print(f"     âš ï¸  Could not read index columns: {e}")
        else:
            print("   (no indexes)")

        # Row count
        cursor.execute("SELECT COUNT(*) FROM ai_models;")
        count = cursor.fetchone()[0]
        print(f"\nğŸ“Š Total rows: {count}")

        if count == 0:
            print("â„¹ï¸  No AI models found in the database yet.")
            return

        # Fetch and display entries
        cursor.execute("""
            SELECT id, name, type, format, file_path, project_id, project_name, nc, classes, 
                   training_input_size, input_size_default, created_at, updated_at
            FROM ai_models
            ORDER BY created_at
        """)
        rows = cursor.fetchall()

        for row in rows:
            print(f"\nğŸ¤– MODEL: {row['name']} (ID: {row['id']})")
            print(f"   ğŸ”§ Type: {row['type']}")
            print(f"   ğŸ“¦ Format: {row['format']}")
            print(f"   ğŸ’¾ File Path: {row['file_path']} {'âœ…' if os.path.exists(row['file_path']) else 'âŒ'}")
            print(f"   ğŸ—ï¸  Project ID: {row['project_id']}")
            print(f"   ğŸ·ï¸  Project Name: {row['project_name']}")
            print(f"   ğŸ¯ Class Count (nc): {row['nc']}")

            # Parse classes JSON
            classes_raw = row['classes']
            classes_list = None
            try:
                if isinstance(classes_raw, str):
                    classes_list = json.loads(classes_raw)
                else:
                    classes_list = classes_raw
            except (json.JSONDecodeError, TypeError) as e:
                print(f"   ğŸ·ï¸  Classes: (could not parse) {classes_raw} â€” {e}")

            if isinstance(classes_list, list):
                print(f"   ğŸ·ï¸  Classes ({len(classes_list)}): {', '.join(map(str, classes_list))}")
            else:
                print(f"   ğŸ·ï¸  Classes: {classes_raw}")

            # Input sizes
            tis = row['training_input_size']
            ids = row['input_size_default']
            print(f"   ğŸ“ Training Input Size: {tis if tis is not None else 'N/A'}")
            print(f"   ğŸ“ Input Size Default: {ids if ids is not None else 'N/A'}")

            # Timestamps
            print(f"   ğŸ“… Created: {row['created_at']}")
            print(f"   ğŸ”„ Updated: {row['updated_at'] if 'updated_at' in row.keys() else 'N/A'}")

    def get_dev_mode_settings_table(self):
        """Show developer mode settings table (password state)"""
        cursor = self.conn.cursor()

        self.print_header("DEV MODE SETTINGS TABLE")

        # Check table existence
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='dev_mode_settings'")
        if not cursor.fetchone():
            print("âŒ dev_mode_settings table does not exist!")
            return

        # Schema
        print("\nğŸ“ Schema:")
        cursor.execute("PRAGMA table_info(dev_mode_settings)")
        for col in cursor.fetchall():
            col_info = f"   - {col[1]} ({col[2]})"
            if col[3]:
                col_info += " NOT NULL"
            if col[4] is not None:
                col_info += f" DEFAULT {col[4]}"
            if col[5]:
                col_info += " PRIMARY KEY"
            print(col_info)

        # Row count
        cursor.execute("SELECT COUNT(*) FROM dev_mode_settings")
        count = cursor.fetchone()[0]
        print(f"\nğŸ“Š Total rows: {count}")

        # Show the first record (if any)
        if count:
            cursor.execute("SELECT id, password_hash, master_password_hash, updated_at FROM dev_mode_settings ORDER BY id LIMIT 1")
            row = cursor.fetchone()
            print(f"\nğŸ—‚ï¸  Current Setting:")
            has_pw = bool(row[1])
            is_default = has_pw and (row[1] == hashlib.sha256(b"0000").hexdigest())
            pw_state = (
                "Default (0000)" if is_default else ("Custom (hidden)" if has_pw else "Not set")
            )
            has_master = bool(row[2])
            is_master_default = has_master and (row[2] == hashlib.sha256(b"gevis").hexdigest())
            master_state = (
                "Default (gevis)" if is_master_default else ("Custom (hidden)" if has_master else "Not set")
            )
            print(f"   id: {row[0]} â€¢ updated_at: {row[3]} â€¢ password: {pw_state} â€¢ master: {master_state}")

    def get_image_transformations_table(self):
        """Get detailed information about image transformations"""
        cursor = self.conn.cursor()
        
        self.print_header("IMAGE TRANSFORMATIONS TABLE")
        
        # Check if image_transformations table exists
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='image_transformations'")
        if not cursor.fetchone():
            print("âŒ image_transformations table does not exist!")
            return
        
        # Get all transformations
        cursor.execute("""
            SELECT id, transformation_type, parameters, is_enabled, order_index, 
                   release_version, category, created_at, status, release_id
            FROM image_transformations
            ORDER BY status, category, order_index, created_at
        """)
        
        transformations = cursor.fetchall()
        
        if not transformations:
            print("âŒ No image transformations found in the database!")
            return
        
        print(f"ğŸ”§ Found {len(transformations)} image transformations in database\n")
        
        # Group transformations by category
        categories = {}
        for transform in transformations:
            category = transform['category'] or 'basic'  # Default to basic if None
            if category not in categories:
                categories[category] = []
            categories[category].append(transform)
        
        # Display transformations by category
        for category, transforms in categories.items():
            self.print_subheader(f"Category: {category.upper()} ({len(transforms)} transformations)")
            
            for transform in transforms:
                print(f"\n   ğŸ”§ TRANSFORMATION: {transform['transformation_type']}")
                print(f"      ğŸ†” ID: {transform['id']}")
                print(f"      âš™ï¸  Parameters: {transform['parameters']}")
                print(f"      âœ… Enabled: {'Yes' if transform['is_enabled'] else 'No'}")
                print(f"      ğŸ“Š Order Index: {transform['order_index']}")
                print(f"      ğŸ·ï¸  Release Version: {transform['release_version']}")
                print(f"      ğŸ”„ Status: {transform['status'] or 'PENDING'}")
                print(f"      ğŸ”— Release ID: {transform['release_id'] or 'None'}")
                print(f"      ğŸ“… Created: {transform['created_at']}")
                
                # Parse and display parameters in a readable format
                try:
                    if transform['parameters']:
                        params = json.loads(transform['parameters']) if isinstance(transform['parameters'], str) else transform['parameters']
                        if isinstance(params, dict) and params:
                            print(f"      ğŸ“‹ Parsed Parameters:")
                            for key, value in params.items():
                                print(f"         - {key}: {value}")
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"      âš ï¸  Could not parse parameters: {e}")
        
        # Statistics
        print(f"\nğŸ“Š TRANSFORMATION STATISTICS:")
        cursor.execute("SELECT category, COUNT(*) FROM image_transformations GROUP BY category")
        category_stats = cursor.fetchall()
        
        print(f"   ğŸ“‹ By Category:")
        for category, count in category_stats:
            print(f"      {category or 'basic'}: {count} transformations")
        
        cursor.execute("SELECT COUNT(*) FROM image_transformations WHERE is_enabled = 1")
        enabled_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM image_transformations WHERE is_enabled = 0")
        disabled_count = cursor.fetchone()[0]
        
        print(f"   ğŸ“‹ By Enabled Status:")
        print(f"      âœ… Enabled: {enabled_count}")
        print(f"      âŒ Disabled: {disabled_count}")
        
        # Status statistics
        cursor.execute("SELECT status, COUNT(*) FROM image_transformations GROUP BY status")
        status_stats = cursor.fetchall()
        
        print(f"   ğŸ“‹ By Workflow Status:")
        for status, count in status_stats:
            status_icon = "ğŸŸ¡" if status == "PENDING" else "ğŸŸ¢" if status == "COMPLETED" else "â“"
            print(f"      {status_icon} {status or 'PENDING'}: {count} transformations")
        
        # Release linking statistics
        cursor.execute("SELECT COUNT(*) FROM image_transformations WHERE release_id IS NOT NULL")
        linked_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM image_transformations WHERE release_id IS NULL")
        unlinked_count = cursor.fetchone()[0]
        
        print(f"   ğŸ“‹ By Release Linking:")
        print(f"      ğŸ”— Linked to Release: {linked_count}")
        print(f"      ğŸ”“ Not Linked: {unlinked_count}")
        
        # Check for unique transformation types
        cursor.execute("SELECT DISTINCT transformation_type FROM image_transformations ORDER BY transformation_type")
        unique_types = cursor.fetchall()
        
        print(f"   ğŸ”§ Unique Types: {', '.join([t[0] for t in unique_types])}")

    def get_releases_table(self):
        """Get detailed information about releases"""
        cursor = self.conn.cursor()
        
        self.print_header("RELEASES TABLE")
        
        # Check if releases table exists
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='releases'")
        if not cursor.fetchone():
            print("âŒ releases table does not exist!")
            return
        
        # Get all releases
        cursor.execute("""
            SELECT r.id, r.project_id, r.name, r.description, r.export_format, 
                   r.task_type, r.datasets_used, r.config, r.total_original_images,
                   r.total_augmented_images, r.final_image_count,
                   r.train_image_count, r.val_image_count, r.test_image_count,
                   r.class_count,r.model_path, r.created_at, p.name as project_name
            FROM releases r
            LEFT JOIN projects p ON r.project_id = p.id
            ORDER BY r.created_at DESC
        """)
        
        releases = cursor.fetchall()
        
        if not releases:
            print("âŒ No releases found in the database!")
            print("â„¹ï¸  This is normal if no dataset releases have been created yet.")
            return
        
        print(f"ğŸš€ Found {len(releases)} releases in database\n")
        
        # Display releases
        for release in releases:
            print(f"\nğŸš€ RELEASE: {release['name']}")
            print(f"   ğŸ†” ID: {release['id']}")
            print(f"   ğŸ—ï¸  Project: {release['project_name']} (ID: {release['project_id']})")
            print(f"   ğŸ“ Description: {release['description'] or 'No description'}")
            print(f"   ğŸ“¦ Export Format: {release['export_format'] or 'Not specified'}")
            print(f"   ğŸ¯ Task Type: {release['task_type'] or 'Not specified'}")
            print(f"   ğŸ“… Created: {release['created_at']}")
            
            # Display image counts
            print(f"   ğŸ“Š Image Counts:")
            print(f"      Original: {release['total_original_images'] or 'N/A'}")
            print(f"      Augmented: {release['total_augmented_images'] or 'N/A'}")
            print(f"      Final: {release['final_image_count'] or 'N/A'}")
            print(f"      Train: {release['train_image_count'] or 'N/A'}")
            print(f"      Val: {release['val_image_count'] or 'N/A'}")
            print(f"      Test: {release['test_image_count'] or 'N/A'}")
            print(f"      Classes: {release['class_count'] or 'N/A'}")
            
            
            # Display model path
            if release['model_path']:
                model_exists = os.path.exists(release['model_path'])
                print(f"   ğŸ’¾ Model Path: {release['model_path']} {'âœ…' if model_exists else 'âŒ'}")
            else:
                print(f"   ğŸ’¾ Model Path: Not specified")
            
            # Parse and display datasets used
            if release['datasets_used']:
                try:
                    datasets = json.loads(release['datasets_used']) if isinstance(release['datasets_used'], str) else release['datasets_used']
                    if isinstance(datasets, list):
                        print(f"   ğŸ“ Datasets Used: {len(datasets)} dataset(s)")
                        for i, dataset_id in enumerate(datasets[:5]):  # Show first 5
                            # Get dataset name
                            cursor.execute("SELECT name FROM datasets WHERE id = ?", (dataset_id,))
                            dataset_result = cursor.fetchone()
                            dataset_name = dataset_result[0] if dataset_result else "Unknown"
                            print(f"      {i+1}. {dataset_name} (ID: {dataset_id})")
                        if len(datasets) > 5:
                            print(f"      ... and {len(datasets)-5} more datasets")
                    else:
                        print(f"   ğŸ“ Datasets Used: {datasets}")
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"   ğŸ“ Datasets Used: Could not parse ({e})")
            else:
                print(f"   ğŸ“ Datasets Used: None specified")
            
            # Parse and display configuration
            if release['config']:
                try:
                    config = json.loads(release['config']) if isinstance(release['config'], str) else release['config']
                    if isinstance(config, dict):
                        print(f"   âš™ï¸  Configuration:")
                        for key, value in config.items():
                            if isinstance(value, dict):
                                print(f"      {key}: {len(value)} settings")
                            elif isinstance(value, list):
                                print(f"      {key}: {len(value)} items")
                            else:
                                print(f"      {key}: {value}")
                    else:
                        print(f"   âš™ï¸  Configuration: {config}")
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"   âš™ï¸  Configuration: Could not parse ({e})")
            else:
                print(f"   âš™ï¸  Configuration: None specified")
        
        # Statistics
        print(f"\nğŸ“Š RELEASE STATISTICS:")
        cursor.execute("SELECT export_format, COUNT(*) FROM releases GROUP BY export_format")
        format_stats = cursor.fetchall()
        
        if format_stats:
            print(f"   ğŸ“¦ Export Formats:")
            for format_type, count in format_stats:
                print(f"      {format_type or 'Unspecified'}: {count} releases")
        
        cursor.execute("SELECT task_type, COUNT(*) FROM releases GROUP BY task_type")
        task_stats = cursor.fetchall()
        
        if task_stats:
            print(f"   ğŸ¯ Task Types:")
            for task_type, count in task_stats:
                print(f"      {task_type or 'Unspecified'}: {count} releases")
        
        # Check for releases with missing files
        cursor.execute("SELECT COUNT(*) FROM releases WHERE model_path IS NOT NULL")
        releases_with_path = cursor.fetchone()[0]
        
        if releases_with_path > 0:
            cursor.execute("SELECT model_path FROM releases WHERE model_path IS NOT NULL")
            paths = cursor.fetchall()
            missing_files = 0
            for path_row in paths:
                if not os.path.exists(path_row[0]):
                    missing_files += 1
            
            print(f"   ğŸ’¾ File Status:")
            print(f"      With model path: {releases_with_path}")
            print(f"      Missing files: {missing_files}")

    def get_transformation_release_relationships(self):
        """Show relationships between transformations and releases"""
        cursor = self.conn.cursor()
        
        self.print_header("TRANSFORMATION-RELEASE RELATIONSHIPS")
        
        # Check if both tables exist
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name IN ('image_transformations', 'releases')")
        tables = [row[0] for row in cursor.fetchall()]
        
        if 'image_transformations' not in tables:
            print("âŒ image_transformations table does not exist!")
            return
        if 'releases' not in tables:
            print("âŒ releases table does not exist!")
            return
        
        # Get transformations with their linked releases
        cursor.execute("""
            SELECT 
                t.id as transform_id,
                t.transformation_type,
                t.status,
                t.release_version,
                t.release_id,
                t.created_at as transform_created,
                r.name as release_name,
                r.created_at as release_created
            FROM image_transformations t
            LEFT JOIN releases r ON t.release_id = r.id
            ORDER BY t.status, t.release_version, t.created_at
        """)
        
        relationships = cursor.fetchall()
        
        if not relationships:
            print("âŒ No transformations found!")
            return
        
        # Group by status
        pending_transforms = [r for r in relationships if r['status'] == 'PENDING' or r['status'] is None]
        completed_transforms = [r for r in relationships if r['status'] == 'COMPLETED']
        
        # Show pending transformations
        if pending_transforms:
            self.print_subheader("ğŸŸ¡ PENDING TRANSFORMATIONS (Not yet in a release)")
            
            # Group by release_version
            version_groups = {}
            for transform in pending_transforms:
                version = transform['release_version']
                if version not in version_groups:
                    version_groups[version] = []
                version_groups[version].append(transform)
            
            for version, transforms in version_groups.items():
                print(f"\n   ğŸ“¦ Release Version: {version}")
                print(f"      ğŸ”„ Status: PENDING ({len(transforms)} transformations)")
                print(f"      ğŸ”— Release ID: None (not yet created)")
                
                for transform in transforms:
                    print(f"         ğŸ”§ {transform['transformation_type']} (ID: {transform['transform_id'][:8]}...)")
                    print(f"            ğŸ“… Created: {transform['transform_created']}")
        
        # Show completed transformations
        if completed_transforms:
            self.print_subheader("ğŸŸ¢ COMPLETED TRANSFORMATIONS (Linked to releases)")
            
            # Group by release
            release_groups = {}
            for transform in completed_transforms:
                release_id = transform['release_id']
                if release_id not in release_groups:
                    release_groups[release_id] = []
                release_groups[release_id].append(transform)
            
            for release_id, transforms in release_groups.items():
                release_name = transforms[0]['release_name'] if transforms[0]['release_name'] else 'Unknown Release'
                release_created = transforms[0]['release_created']
                
                print(f"\n   ğŸš€ Release: {release_name}")
                print(f"      ğŸ†” Release ID: {release_id}")
                print(f"      ğŸ”„ Status: COMPLETED ({len(transforms)} transformations)")
                print(f"      ğŸ“… Release Created: {release_created}")
                
                for transform in transforms:
                    print(f"         ğŸ”§ {transform['transformation_type']} (ID: {transform['transform_id'][:8]}...)")
                    print(f"            ğŸ“… Transform Created: {transform['transform_created']}")
        
        # Summary statistics
        print(f"\nğŸ“Š RELATIONSHIP SUMMARY:")
        print(f"   ğŸŸ¡ Pending Transformations: {len(pending_transforms)}")
        print(f"   ğŸŸ¢ Completed Transformations: {len(completed_transforms)}")
        print(f"   ğŸ“¦ Unique Release Versions: {len(set(r['release_version'] for r in relationships if r['release_version']))}")
        print(f"   ğŸš€ Linked Releases: {len(set(r['release_id'] for r in completed_transforms if r['release_id']))}")

    def get_database_statistics(self):
        """Get overall database statistics"""
        cursor = self.conn.cursor()
        
        self.print_header("DATABASE STATISTICS")
        
        # Projects
        cursor.execute("SELECT COUNT(*) FROM projects")
        project_count = cursor.fetchone()[0]
        
        # Datasets
        cursor.execute("SELECT COUNT(*) FROM datasets")
        dataset_count = cursor.fetchone()[0]
        
        # Images
        cursor.execute("SELECT COUNT(*) FROM images")
        image_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM images WHERE is_labeled = 1")
        labeled_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM images WHERE is_labeled = 0")
        unlabeled_count = cursor.fetchone()[0]
        
        # Annotations
        cursor.execute("SELECT COUNT(*) FROM annotations")
        annotation_count = cursor.fetchone()[0]
        
        # Labels
        cursor.execute("SELECT COUNT(*) FROM labels")
        label_count = cursor.fetchone()[0] if cursor.rowcount != -1 else 0
        
        # Split sections (from images table)
        cursor.execute("SELECT split_section, COUNT(*) FROM images GROUP BY split_section")
        split_stats = cursor.fetchall()
        
        print(f"ğŸ“Š OVERALL STATISTICS:")
        print(f"   ğŸ—ï¸  Projects: {project_count}")
        print(f"   ğŸ“ Datasets: {dataset_count}")
        print(f"   ğŸ–¼ï¸  Total Images: {image_count}")
        print(f"   âœ… Labeled Images: {labeled_count}")
        print(f"   âŒ Unlabeled Images: {unlabeled_count}")
        print(f"   ğŸ¯ Total Annotations: {annotation_count}")
        print(f"   ğŸ”– Total Labels: {label_count}")
        
        print(f"\nğŸ“ˆ SPLIT SECTION DISTRIBUTION:")
        for split_section, count in split_stats:
            print(f"   {split_section}: {count} images")
        
        # Database file info
        db_size = os.path.getsize(self.db_path)
        db_size_mb = db_size / (1024 * 1024)
        print(f"\nğŸ’¾ DATABASE FILE:")
        print(f"   Path: {os.path.abspath(self.db_path)}")
        print(f"   Size: {db_size_mb:.2f} MB")
        print(f"   Last Modified: {datetime.fromtimestamp(os.path.getmtime(self.db_path))}")
    
    def run_full_debug(self):
        """Run complete database debug analysis"""
        if not self.connect():
            return
        
        try:
            print("ğŸ” Starting Database Debug Analysis...")
            print(f"ğŸ“… Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            self.get_database_statistics()
            self.get_table_info()
            self.get_ai_models_table()  # Add AI models table analysis
            self.get_dev_mode_settings_table()  # Show dev-mode settings
            self.get_training_sessions_table()  # Training sessions table analysis
            self.get_projects_overview()
            self.get_datasets_detailed()
            self.get_labels_table()  # Add labels table analysis
            self.get_releases_table()  # Add releases table analysis
            self.get_image_transformations_table()  # Add image transformations table analysis
            self.get_image_transformations_detailed()  # Add detailed dual-value transformations analysis
            self.get_transformation_release_relationships()  # Show transformation-release relationships
            self.get_images_detailed()
            self.get_annotations_summary()
            self.get_detailed_annotations()
            self.get_file_system_vs_database()
            
            self.print_header("DEBUG ANALYSIS COMPLETE", "ğŸ‰")
            print("âœ… All database information has been displayed above.")
            print("ğŸ’¡ Use this information to debug any data inconsistencies.")
            
        except Exception as e:
            print(f"âŒ Error during debug analysis: {e}")
        finally:
            self.close()


def main():
    """Main function to run the database debugger"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Database debugging tool')
    parser.add_argument('--db', type=str, default='database.db', help='Path to database file')
    parser.add_argument('--labels', action='store_true', help='Show only labels table data')
    parser.add_argument('--ai-models', action='store_true', help='Show only ai_models table data')
    args = parser.parse_args()
    
    db_path = args.db
    
    # Check if database file exists
    if not os.path.exists(db_path):
        print(f"âŒ Database file not found: {db_path}")
        return
    
    print("ğŸ”§ Database Debug Viewer")
    print("=" * 50)
    print(f"Using database file: {db_path}")
    
    # Create the debugger
    debugger = DatabaseDebugger(db_path)
    
    if args.labels:
        # Only show labels table
        if debugger.connect():
            debugger.get_labels_table()
            debugger.close()
    elif args.ai_models:
        # Only show ai_models table
        if debugger.connect():
            debugger.get_ai_models_table()
            debugger.close()
    else:
        # Run full debug
        debugger.run_full_debug()

if __name__ == "__main__":
    main()
